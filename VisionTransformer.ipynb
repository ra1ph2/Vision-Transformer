{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VisionTransformer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlyYLvUVXjacS0gJxqdAW+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ra1ph2/Vision-Transformer/blob/main/VisionTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7v2dPqfZFIV"
      },
      "source": [
        "#### Libraries Imported"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bQIxfD9Ep0y"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFc5EfTgZIBk"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idmPOFlDIGDZ"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, embed_dim, heads=8, activation=None, dropout=0.1):\n",
        "        super(Attention, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.embed_dim = embed_dim\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        if activation == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        else:\n",
        "            self.activation = nn.Identity()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "        batch_size, seq_len, embed_dim = inp.size()\n",
        "        assert embed_dim == self.embed_dim\n",
        "\n",
        "        query = self.activation(self.query(inp))\n",
        "        key   = self.activation(self.key(inp))\n",
        "        value = self.activation(self.value(inp))\n",
        "\n",
        "        # output of _reshape_heads(): (batch_size * heads, seq_len, reduced_dim) | reduced_dim = embed_dim // heads\n",
        "        query = self._reshape_heads(query)\n",
        "        key   = self._reshape_heads(key)\n",
        "        value = self._reshape_heads(value)\n",
        "\n",
        "        # attention_scores: (batch_size * heads, seq_len, seq_len) | Softmaxed along the last dimension\n",
        "        attention_scores = self.softmax(torch.matmul(query, key.transpose(1, 2)))\n",
        "\n",
        "        # out: (batch_size * heads, seq_len, reduced_dim)\n",
        "        out = torch.matmul(self.dropout(attention_scores), value)\n",
        "        \n",
        "        # output of _reshape_heads_back(): (batch_size, seq_len, embed_size)\n",
        "        out = self._reshape_heads_back(out)\n",
        "\n",
        "        return out, attention_scores\n",
        "\n",
        "    def _reshape_heads(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "        batch_size, seq_len, embed_dim = inp.size()\n",
        "\n",
        "        reduced_dim = self.embed_dim // self.heads\n",
        "        assert reduced_dim * self.heads == self.embed_dim\n",
        "        out = inp.reshape(batch_size, seq_len, self.heads, reduced_dim)\n",
        "        out = out.permute(0, 2, 1, 3)\n",
        "        out = out.reshape(-1, seq_len, reduced_dim)\n",
        "\n",
        "        # out: (batch_size * heads, seq_len, reduced_dim)\n",
        "        return out\n",
        "\n",
        "    def _reshape_heads_back(self, inp):\n",
        "        # inp: (batch_size * heads, seq_len, reduced_dim) | reduced_dim = embed_dim // heads\n",
        "        batch_size_mul_heads, seq_len, reduced_dim = inp.size()\n",
        "        batch_size = batch_size_mul_heads // self.heads\n",
        "\n",
        "        out = inp.reshape(batch_size, self.heads, seq_len, reduced_dim)\n",
        "        out = out.permute(0, 2, 1, 3)\n",
        "        out = out.reshape(batch_size, seq_len, self.embed_dim)\n",
        "\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "        return out"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOGwfjHJQR_M",
        "outputId": "54226e2e-9fd2-4415-b961-7ce0fdcfe3e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "attention = Attention(embed_dim=4, heads=2, activation=None)\n",
        "attention_lib = nn.MultiheadAttention(embed_dim=4, num_heads=2)\n",
        "inp = torch.ones((1, 2, 4))\n",
        "print(inp)\n",
        "out, wts = attention(inp)\n",
        "print(out)\n",
        "print(wts)\n",
        "out_lib, out_wts = attention_lib(inp.permute(1, 0, 2), inp.permute(1, 0, 2), inp.permute(1, 0, 2))\n",
        "print(out_lib.permute(1, 0, 2))\n",
        "print(out_wts)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n",
            "tensor([[[-0.1458, -0.9517, -0.5752,  0.0712],\n",
            "         [-0.0729, -0.4758, -0.2876,  0.0356]]], grad_fn=<UnsafeViewBackward>)\n",
            "tensor([[[0.5000, 0.5000],\n",
            "         [0.5000, 0.5000]],\n",
            "\n",
            "        [[0.5000, 0.5000],\n",
            "         [0.5000, 0.5000]]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([[[-0.4409,  0.7654,  0.4589, -0.5832],\n",
            "         [-0.4409,  0.7654,  0.4589, -0.5832]]], grad_fn=<PermuteBackward>)\n",
            "tensor([[[0.5000, 0.5000],\n",
            "         [0.5000, 0.5000]]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYemII1gElcK"
      },
      "source": [
        "# Check if Dropout should be used after second Linear Layer\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, embed_dim, forward_expansion=1, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim * forward_expansion)\n",
        "        self.activation = nn.GELU()\n",
        "        self.fc2 = nn.Linear(embed_dim * forward_expansion, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "        batch_size, seq_len, embed_dim = inp.size()\n",
        "        assert embed_dim == self.embed_dim\n",
        "\n",
        "        out = self.dropout(self.activation(self.fc1(inp)))\n",
        "        # out = self.dropout(self.fc2(out))\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "        return out "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1r7Cak2F9CN",
        "outputId": "9a17b27c-88c1-4599-910b-758a39e060d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ff = FeedForward(8, 1)\n",
        "inp = torch.ones((1, 2, 8))\n",
        "print(inp)\n",
        "out = ff(inp)\n",
        "print(out)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
            "tensor([[[-0.0409, -0.0025, -0.0943, -0.0105, -0.0891, -0.0134, -0.1431,\n",
            "           0.3287],\n",
            "         [-0.0265, -0.0158, -0.0895,  0.0139, -0.0681, -0.0181, -0.1407,\n",
            "           0.3108]]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMrCi7DNGvCc"
      },
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, heads=8, activation=None, forward_expansion=1, dropout=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.attention = Attention(embed_dim, heads, activation, dropout)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.feed_forward = FeedForward(embed_dim, forward_expansion, dropout)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "        batch_size, seq_len, embed_dim = inp.size()\n",
        "        assert embed_dim == self.embed_dim\n",
        "\n",
        "        res = inp\n",
        "        out = self.norm1(inp)\n",
        "        out, _ = self.attention(out)\n",
        "        out = out + res\n",
        "        \n",
        "        res = out\n",
        "        out = self.norm2(out)\n",
        "        out = self.feed_forward(out)\n",
        "        out = out + res\n",
        "\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "        return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IomPGN9UJj1j",
        "outputId": "89f83d39-cbc6-4186-af12-c7b6f4e43d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tb = TransformerBlock(8, 2)\n",
        "inp = torch.ones((1, 2, 8))\n",
        "print(inp)\n",
        "out = tb(inp)\n",
        "print(out)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
            "tensor([[[1.2714, 1.6808, 1.0581, 1.8078, 0.4354, 1.0091, 0.9663, 1.1954],\n",
            "         [1.2904, 1.6790, 1.0655, 1.7437, 0.5846, 1.0650, 0.9050, 1.2332]]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcBcReoPJ4NC"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embed_dim, layers, heads=8, activation=None, forward_expansion=1, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.trans_blocks = nn.ModuleList(\n",
        "            [TransformerBlock(embed_dim, heads, activation, forward_expansion, dropout) for i in range(layers)]\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        out = inp\n",
        "        for block in self.trans_blocks:\n",
        "            out = block(out)\n",
        "\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "        return out"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfxmE-mJLILR",
        "outputId": "c9b4402d-f9fc-477f-cc92-e538edf170fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tb = TransformerBlock(8, 2)\n",
        "trans = Transformer(8, 1, 2)\n",
        "inp = torch.ones((1, 2, 8))\n",
        "print(inp)\n",
        "out = tb(inp)\n",
        "print(out)\n",
        "out = trans(inp)\n",
        "print(out)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
            "tensor([[[0.9370, 0.9729, 1.1449, 1.0035, 0.4312, 0.4503, 1.0191, 0.7539],\n",
            "         [0.8959, 1.1752, 1.3447, 1.2614, 0.3136, 0.2084, 0.8908, 0.8482]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "tensor([[[0.8253, 1.3689, 1.1571, 0.5761, 0.8079, 0.9461, 1.2345, 0.2657],\n",
            "         [0.8667, 1.3327, 1.1235, 0.6152, 0.8009, 0.9217, 1.2245, 0.2974]]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRN2k5-kLWYG"
      },
      "source": [
        "# Not Exactly Same as Paper | Check if Dropout should be used here\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, embed_dim, classes, dropout=0.1):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.classes = classes\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim // 2)\n",
        "        self.activation = nn.GELU()\n",
        "        self.fc2 = nn.Linear(embed_dim // 2, classes)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, embed_dim)\n",
        "        batch_size, embed_dim = inp.size()\n",
        "        assert embed_dim == self.embed_dim\n",
        "\n",
        "        out = self.dropout(self.activation(self.fc1(inp)))\n",
        "        out = self.softmax(self.fc2(out))\n",
        "\n",
        "        # out: (batch_size, embed_dim) | SoftMaxed along the last dimension\n",
        "        return out"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfBFnhBhOFIB",
        "outputId": "f1698f2e-e2e6-4b91-d269-1734731fb1bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ch = ClassificationHead(8, 2)\n",
        "inp = torch.ones((2, 8))\n",
        "print(inp)\n",
        "out = ch(inp)\n",
        "print(out)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "tensor([[0.6724, 0.3276],\n",
            "        [0.6441, 0.3559]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-8nXI7gPxIs"
      },
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self, patch_size, max_len, embed_dim, classes, layers, heads=8, activation=None, forward_expansion=1, dropout=0.1):\n",
        "        super(VisionTransformer, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.patch_to_embed = nn.Linear(patch_size * patch_size * 3, embed_dim)\n",
        "        self.position_embed = nn.Parameter(torch.randn((max_len, embed_dim)))\n",
        "        self.transformer = Transformer(embed_dim, layers, heads, activation, forward_expansion, dropout)\n",
        "        self.classification_head = ClassificationHead(embed_dim, classes)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # inp: (batch_size, seq_len, patch_size, patch_size, 3) | seq_len would be (width*height)/(patch_size**2)\n",
        "        batch_size, seq_len, patch_size, _, channels = inp.size()\n",
        "        assert patch_size == self.patch_size\n",
        "        assert channels == 3\n",
        "\n",
        "        out = inp.reshape(batch_size, seq_len, -1)\n",
        "        out = self.patch_to_embed(out)\n",
        "        # out: (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        class_token = torch.randn((batch_size, 1, self.embed_dim))\n",
        "        out = torch.cat([class_token, out], dim=1)\n",
        "        # out: (batch_size, seq_len+1, embed_dim)\n",
        "\n",
        "        position_embed = self.position_embed[:seq_len+1]\n",
        "        position_embed = position_embed.unsqueeze(0).expand(batch_size, seq_len+1, self.embed_dim)\n",
        "        out = out + position_embed\n",
        "        # out: (batch_size, seq_len+1, embed_dim) | Added Positional Embeddings\n",
        "\n",
        "        out = self.transformer(out)\n",
        "        # out: (batch_size, seq_len+1, embed_dim) \n",
        "        class_token = out[:, 0]\n",
        "        # class_token: (batch_size, embed_dim)\n",
        "\n",
        "        class_out = self.classification_head(class_token)\n",
        "        # class_out: (batch_size, classes)\n",
        "        \n",
        "        return class_out, out"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W82aFCPPWIus",
        "outputId": "c04c92e2-e2b4-49af-dbed-e030b797f95c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vit = VisionTransformer(2, 3, 8, 2, 2)\n",
        "inp = torch.ones((2, 2, 2, 2, 3))\n",
        "print(inp)\n",
        "class_out, out = vit(inp)\n",
        "print(class_out)\n",
        "print(class_out.shape)\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[[1., 1., 1.],\n",
            "           [1., 1., 1.]],\n",
            "\n",
            "          [[1., 1., 1.],\n",
            "           [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "         [[[1., 1., 1.],\n",
            "           [1., 1., 1.]],\n",
            "\n",
            "          [[1., 1., 1.],\n",
            "           [1., 1., 1.]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[1., 1., 1.],\n",
            "           [1., 1., 1.]],\n",
            "\n",
            "          [[1., 1., 1.],\n",
            "           [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "         [[[1., 1., 1.],\n",
            "           [1., 1., 1.]],\n",
            "\n",
            "          [[1., 1., 1.],\n",
            "           [1., 1., 1.]]]]])\n",
            "tensor([[0.7722, 0.2278],\n",
            "        [0.5310, 0.4690]], grad_fn=<SoftmaxBackward>)\n",
            "torch.Size([2, 2])\n",
            "tensor([[[-0.1050, -0.3875, -1.4965, -1.2352, -2.4860,  0.8516,  0.5158,\n",
            "          -2.4766],\n",
            "         [-0.4389, -0.4218,  1.7999, -0.8428,  0.4959, -0.5753,  0.6173,\n",
            "          -1.8818],\n",
            "         [-0.5806,  1.7895,  2.2520, -1.6987, -1.4750,  1.9487,  0.4231,\n",
            "          -0.1351]],\n",
            "\n",
            "        [[ 2.2784,  1.2812,  1.4759, -0.6443, -3.0957, -2.5200,  2.0057,\n",
            "          -0.5107],\n",
            "         [ 0.1411, -0.2414,  0.9622, -1.1537,  0.7594, -0.6575,  1.3814,\n",
            "          -1.6858],\n",
            "         [-0.0932,  2.4765,  1.6200, -1.5750, -1.0060,  2.0158,  0.9577,\n",
            "           0.0113]]], grad_fn=<AddBackward0>)\n",
            "torch.Size([2, 3, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}